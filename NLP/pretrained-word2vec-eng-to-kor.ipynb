{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NJ3kR_9AeUj9"
   },
   "source": [
    "# 사전 훈련된 Word2Vec을 이용한 영어-한국어 번역 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "yI47CHoS7k9Z",
    "outputId": "6e156e48-55e7-44a5-af7d-a622c07aecdc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/HK/Desktop/GitHub/Deep-Learning/NLP')\n",
    "\n",
    "import gensim\n",
    "import nltk\n",
    "import konlpy\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z-8EDzFJeTdD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F1e0NtzvVS4P"
   },
   "source": [
    "> ### 사전 훈련된 워드벡터 준비\n",
    "\n",
    "- 언어별 Word2Vec 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "pbKm6wPbAAf2",
    "outputId": "1e1a5fcd-b780-404c-f962-4bf747ce2859"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:743: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  \"C extension not loaded, training will be slow. \"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "word2vec_kor = Word2Vec.load('Data/ko.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "rgO7LgYWDCqL",
    "outputId": "600c8a97-289d-4ec8-af85-b82eecca3dbb"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec_eng = KeyedVectors.load_word2vec_format('Data/GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QR5wiAxScvxG"
   },
   "source": [
    "> ### 데이터 준비\n",
    "\n",
    "- 출처: Manythings.org http://www.manythings.org/anki/kor-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "NiFf9dXIdunu",
    "outputId": "c0c6c068-592b-45ca-86db-640085840367"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909 observations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Tom isn't skinny.</td>\n",
       "      <td>톰은 마르지 않았다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>Tom lives in a small apartment on Park Street.</td>\n",
       "      <td>톰은 파크 스트리트의 작은 아파트에서 살고 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>I don't want to throw that away.</td>\n",
       "      <td>나는 그것을 버리고 싶지 않다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>We've been worried.</td>\n",
       "      <td>계속 걱정했어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>It's not always possible to eat well when you'...</td>\n",
       "      <td>당신이 세계를 여행하는 동안, 항상 잘먹는 것이 가능하지는 않습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>There are a lot of sheep in the pasture.</td>\n",
       "      <td>목초지에 양이 많이 있다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>Tom has something to do right now.</td>\n",
       "      <td>톰은 당장 할일이 있어.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>You'll regret it.</td>\n",
       "      <td>너 후회할거야.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Can I go now?</td>\n",
       "      <td>이제 가도 되나요?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Tom vomited blood.</td>\n",
       "      <td>톰은 피를 토했다.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                source  \\\n",
       "156                                  Tom isn't skinny.   \n",
       "839     Tom lives in a small apartment on Park Street.   \n",
       "617                   I don't want to throw that away.   \n",
       "205                                We've been worried.   \n",
       "907  It's not always possible to eat well when you'...   \n",
       "770           There are a lot of sheep in the pasture.   \n",
       "683                 Tom has something to do right now.   \n",
       "163                                  You'll regret it.   \n",
       "45                                       Can I go now?   \n",
       "178                                 Tom vomited blood.   \n",
       "\n",
       "                                     target  \n",
       "156                             톰은 마르지 않았다.  \n",
       "839             톰은 파크 스트리트의 작은 아파트에서 살고 있다.  \n",
       "617                       나는 그것을 버리고 싶지 않다.  \n",
       "205                                계속 걱정했어.  \n",
       "907  당신이 세계를 여행하는 동안, 항상 잘먹는 것이 가능하지는 않습니다.  \n",
       "770                          목초지에 양이 많이 있다.  \n",
       "683                           톰은 당장 할일이 있어.  \n",
       "163                                너 후회할거야.  \n",
       "45                               이제 가도 되나요?  \n",
       "178                              톰은 피를 토했다.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = pd.read_table('Data/kor.txt', names = ['source', 'target'])\n",
    "print(len(lines), 'observations')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "ODCr0fTDjKMp",
    "outputId": "6deb8b9e-52e7-4fad-b269-d8ed3cf94947"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Tie your shoelaces.</td>\n",
       "      <td>&lt;sos&gt; 신발끈을 묶으세요. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>Everybody here except me has done that.</td>\n",
       "      <td>&lt;sos&gt; 나 빼고 여기에 있는 사람 모두 그것을 했다. (한 적이 있다.) &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>I don't know either.</td>\n",
       "      <td>&lt;sos&gt; 나도 몰라. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>I dislike cold weather.</td>\n",
       "      <td>&lt;sos&gt; 나는 추운 날씨를 싫어한다. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Sorry, I'm late.</td>\n",
       "      <td>&lt;sos&gt; 늦어서 미안합니다. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I don't lie.</td>\n",
       "      <td>&lt;sos&gt; 나는 거짓말 하지 않습니다. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>It is already nine o'clock.</td>\n",
       "      <td>&lt;sos&gt; 벌써 아홉시다. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>We'll take care of that.</td>\n",
       "      <td>&lt;sos&gt; 우리가 그것을 맡겠다. (처리하겠다.) &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>Tom told Mary he wouldn't let her go by herself.</td>\n",
       "      <td>&lt;sos&gt; 톰은 메리에게 그는 그녀를 혼자 가게 하지는 않겠다고 말했다. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>His behavior aroused my suspicions.</td>\n",
       "      <td>&lt;sos&gt; 그의 행동은 나에게 의심을 불러일으켰다. &lt;eos&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               source  \\\n",
       "203                               Tie your shoelaces.   \n",
       "751           Everybody here except me has done that.   \n",
       "221                              I don't know either.   \n",
       "333                           I dislike cold weather.   \n",
       "121                                  Sorry, I'm late.   \n",
       "34                                       I don't lie.   \n",
       "470                       It is already nine o'clock.   \n",
       "385                          We'll take care of that.   \n",
       "853  Tom told Mary he wouldn't let her go by herself.   \n",
       "692               His behavior aroused my suspicions.   \n",
       "\n",
       "                                               target  \n",
       "203                            <sos> 신발끈을 묶으세요. <eos>  \n",
       "751  <sos> 나 빼고 여기에 있는 사람 모두 그것을 했다. (한 적이 있다.) <eos>  \n",
       "221                                <sos> 나도 몰라. <eos>  \n",
       "333                       <sos> 나는 추운 날씨를 싫어한다. <eos>  \n",
       "121                            <sos> 늦어서 미안합니다. <eos>  \n",
       "34                        <sos> 나는 거짓말 하지 않습니다. <eos>  \n",
       "470                              <sos> 벌써 아홉시다. <eos>  \n",
       "385                 <sos> 우리가 그것을 맡겠다. (처리하겠다.) <eos>  \n",
       "853    <sos> 톰은 메리에게 그는 그녀를 혼자 가게 하지는 않겠다고 말했다. <eos>  \n",
       "692                <sos> 그의 행동은 나에게 의심을 불러일으켰다. <eos>  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.target = lines.target.apply(lambda x : '<sos> ' + x + ' <eos>')\n",
    "lines.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_t = Tokenizer()\n",
    "source_t.fit_on_texts(lines.source)\n",
    "source_vocab_size = len(source_t.word_index) + 1\n",
    "\n",
    "target_t = Tokenizer()\n",
    "target_t.fit_on_texts(lines.target)\n",
    "target_vocab_size = len(target_t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1170\n",
      "2049\n"
     ]
    }
   ],
   "source": [
    "print(source_vocab_size)\n",
    "print(target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = source_t.texts_to_sequences(lines.source)\n",
    "source_max_length = max(len(l) for l in encoder_input_data)\n",
    "\n",
    "decoder_input_data = target_t.texts_to_sequences(lines.target)\n",
    "decoder_target_data = [l[1:] for l in decoder_input_data]\n",
    "target_max_length = max(len(l) for l in decoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "17\n"
     ]
    }
   ],
   "source": [
    "print(source_max_length)\n",
    "print(target_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92]\n",
      "[1, 264, 2]\n",
      "[264, 2]\n"
     ]
    }
   ],
   "source": [
    "print(encoder_input_data[0])\n",
    "print(decoder_input_data[0])\n",
    "print(decoder_target_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = pad_sequences(\n",
    "    encoder_input_data, maxlen = source_max_length, padding = 'post')\n",
    "decoder_input_data = pad_sequences(\n",
    "    decoder_input_data, maxlen = target_max_length, padding = 'post')\n",
    "decoder_target_data = pad_sequences(\n",
    "    decoder_target_data, maxlen = target_max_length, padding = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n",
      "no pretrained vector\n"
     ]
    }
   ],
   "source": [
    "encoder_embedding_dim = word2vec_eng.vector_size\n",
    "encoder_pretrained_embedding = np.zeros((source_vocab_size, encoder_embedding_dim))\n",
    "\n",
    "for word, i in source_t.word_index.items():\n",
    "    if word2vec_eng.vocab.get(word) is not None:\n",
    "        encoder_pretrained_embedding[i] = word2vec_eng.get_vector(word)\n",
    "    else:\n",
    "        print('no pretrained vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.22558594, -0.01953125,  0.09082031, ...,  0.02819824,\n",
       "        -0.17773438, -0.00604248],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.171875  ,  0.00543213, -0.10400391, ...,  0.05004883,\n",
       "         0.25      ,  0.18066406],\n",
       "       [ 0.04858398, -0.05444336,  0.08349609, ...,  0.03442383,\n",
       "         0.0291748 ,  0.07421875],\n",
       "       [ 0.35351562,  0.07080078,  0.03588867, ..., -0.04394531,\n",
       "         0.00787354,  0.02648926]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_embedding_dim = word2vec_kor.vector_size\n",
    "decoder_pretrained_embedding = np.zeros((target_vocab_size, decoder_embedding_dim))\n",
    "\n",
    "for word, i in target_t.word_index.items():\n",
    "    if word2vec_kor.vocabulary.get(word) is not None:\n",
    "        encoder_pretrained_embedding[i] = word2vec_eng.get_vector(word)\n",
    "    else:\n",
    "        print('no pretrained vector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "사전 학습된 Word2Vec 영어-한국어 번역 모형.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
